{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/patila06/.pyenv/versions/3.10.12/envs/build_sparse_autoencoder_venv_310/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import sparse_autoencoder\n",
    "\n",
    "import blobfile as bf\n",
    "import transformer_lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2 into HookedTransformer\n",
      "embed.W_E torch.Size([50257, 768])\n",
      "pos_embed.W_pos torch.Size([1024, 768])\n",
      "blocks.0.attn.W_Q torch.Size([12, 768, 64])\n",
      "blocks.0.attn.W_K torch.Size([12, 768, 64])\n",
      "blocks.0.attn.W_V torch.Size([12, 768, 64])\n",
      "blocks.0.attn.W_O torch.Size([12, 64, 768])\n",
      "blocks.0.attn.b_Q torch.Size([12, 64])\n",
      "blocks.0.attn.b_K torch.Size([12, 64])\n",
      "blocks.0.attn.b_V torch.Size([12, 64])\n",
      "blocks.0.attn.b_O torch.Size([768])\n",
      "blocks.0.attn.mask torch.Size([1024, 1024])\n",
      "blocks.0.attn.IGNORE torch.Size([])\n",
      "blocks.0.mlp.W_in torch.Size([768, 3072])\n",
      "blocks.0.mlp.b_in torch.Size([3072])\n",
      "blocks.0.mlp.W_out torch.Size([3072, 768])\n",
      "blocks.0.mlp.b_out torch.Size([768])\n",
      "blocks.1.attn.W_Q torch.Size([12, 768, 64])\n",
      "blocks.1.attn.W_K torch.Size([12, 768, 64])\n",
      "blocks.1.attn.W_V torch.Size([12, 768, 64])\n",
      "blocks.1.attn.W_O torch.Size([12, 64, 768])\n",
      "blocks.1.attn.b_Q torch.Size([12, 64])\n",
      "blocks.1.attn.b_K torch.Size([12, 64])\n",
      "blocks.1.attn.b_V torch.Size([12, 64])\n",
      "blocks.1.attn.b_O torch.Size([768])\n",
      "blocks.1.attn.mask torch.Size([1024, 1024])\n",
      "blocks.1.attn.IGNORE torch.Size([])\n",
      "blocks.1.mlp.W_in torch.Size([768, 3072])\n",
      "blocks.1.mlp.b_in torch.Size([3072])\n",
      "blocks.1.mlp.W_out torch.Size([3072, 768])\n",
      "blocks.1.mlp.b_out torch.Size([768])\n",
      "blocks.2.attn.W_Q torch.Size([12, 768, 64])\n",
      "blocks.2.attn.W_K torch.Size([12, 768, 64])\n",
      "blocks.2.attn.W_V torch.Size([12, 768, 64])\n",
      "blocks.2.attn.W_O torch.Size([12, 64, 768])\n",
      "blocks.2.attn.b_Q torch.Size([12, 64])\n",
      "blocks.2.attn.b_K torch.Size([12, 64])\n",
      "blocks.2.attn.b_V torch.Size([12, 64])\n",
      "blocks.2.attn.b_O torch.Size([768])\n",
      "blocks.2.attn.mask torch.Size([1024, 1024])\n",
      "blocks.2.attn.IGNORE torch.Size([])\n",
      "blocks.2.mlp.W_in torch.Size([768, 3072])\n",
      "blocks.2.mlp.b_in torch.Size([3072])\n",
      "blocks.2.mlp.W_out torch.Size([3072, 768])\n",
      "blocks.2.mlp.b_out torch.Size([768])\n",
      "blocks.3.attn.W_Q torch.Size([12, 768, 64])\n",
      "blocks.3.attn.W_K torch.Size([12, 768, 64])\n",
      "blocks.3.attn.W_V torch.Size([12, 768, 64])\n",
      "blocks.3.attn.W_O torch.Size([12, 64, 768])\n",
      "blocks.3.attn.b_Q torch.Size([12, 64])\n",
      "blocks.3.attn.b_K torch.Size([12, 64])\n",
      "blocks.3.attn.b_V torch.Size([12, 64])\n",
      "blocks.3.attn.b_O torch.Size([768])\n",
      "blocks.3.attn.mask torch.Size([1024, 1024])\n",
      "blocks.3.attn.IGNORE torch.Size([])\n",
      "blocks.3.mlp.W_in torch.Size([768, 3072])\n",
      "blocks.3.mlp.b_in torch.Size([3072])\n",
      "blocks.3.mlp.W_out torch.Size([3072, 768])\n",
      "blocks.3.mlp.b_out torch.Size([768])\n",
      "blocks.4.attn.W_Q torch.Size([12, 768, 64])\n",
      "blocks.4.attn.W_K torch.Size([12, 768, 64])\n",
      "blocks.4.attn.W_V torch.Size([12, 768, 64])\n",
      "blocks.4.attn.W_O torch.Size([12, 64, 768])\n",
      "blocks.4.attn.b_Q torch.Size([12, 64])\n",
      "blocks.4.attn.b_K torch.Size([12, 64])\n",
      "blocks.4.attn.b_V torch.Size([12, 64])\n",
      "blocks.4.attn.b_O torch.Size([768])\n",
      "blocks.4.attn.mask torch.Size([1024, 1024])\n",
      "blocks.4.attn.IGNORE torch.Size([])\n",
      "blocks.4.mlp.W_in torch.Size([768, 3072])\n",
      "blocks.4.mlp.b_in torch.Size([3072])\n",
      "blocks.4.mlp.W_out torch.Size([3072, 768])\n",
      "blocks.4.mlp.b_out torch.Size([768])\n",
      "blocks.5.attn.W_Q torch.Size([12, 768, 64])\n",
      "blocks.5.attn.W_K torch.Size([12, 768, 64])\n",
      "blocks.5.attn.W_V torch.Size([12, 768, 64])\n",
      "blocks.5.attn.W_O torch.Size([12, 64, 768])\n",
      "blocks.5.attn.b_Q torch.Size([12, 64])\n",
      "blocks.5.attn.b_K torch.Size([12, 64])\n",
      "blocks.5.attn.b_V torch.Size([12, 64])\n",
      "blocks.5.attn.b_O torch.Size([768])\n",
      "blocks.5.attn.mask torch.Size([1024, 1024])\n",
      "blocks.5.attn.IGNORE torch.Size([])\n",
      "blocks.5.mlp.W_in torch.Size([768, 3072])\n",
      "blocks.5.mlp.b_in torch.Size([3072])\n",
      "blocks.5.mlp.W_out torch.Size([3072, 768])\n",
      "blocks.5.mlp.b_out torch.Size([768])\n",
      "blocks.6.attn.W_Q torch.Size([12, 768, 64])\n",
      "blocks.6.attn.W_K torch.Size([12, 768, 64])\n",
      "blocks.6.attn.W_V torch.Size([12, 768, 64])\n",
      "blocks.6.attn.W_O torch.Size([12, 64, 768])\n",
      "blocks.6.attn.b_Q torch.Size([12, 64])\n",
      "blocks.6.attn.b_K torch.Size([12, 64])\n",
      "blocks.6.attn.b_V torch.Size([12, 64])\n",
      "blocks.6.attn.b_O torch.Size([768])\n",
      "blocks.6.attn.mask torch.Size([1024, 1024])\n",
      "blocks.6.attn.IGNORE torch.Size([])\n",
      "blocks.6.mlp.W_in torch.Size([768, 3072])\n",
      "blocks.6.mlp.b_in torch.Size([3072])\n",
      "blocks.6.mlp.W_out torch.Size([3072, 768])\n",
      "blocks.6.mlp.b_out torch.Size([768])\n",
      "blocks.7.attn.W_Q torch.Size([12, 768, 64])\n",
      "blocks.7.attn.W_K torch.Size([12, 768, 64])\n",
      "blocks.7.attn.W_V torch.Size([12, 768, 64])\n",
      "blocks.7.attn.W_O torch.Size([12, 64, 768])\n",
      "blocks.7.attn.b_Q torch.Size([12, 64])\n",
      "blocks.7.attn.b_K torch.Size([12, 64])\n",
      "blocks.7.attn.b_V torch.Size([12, 64])\n",
      "blocks.7.attn.b_O torch.Size([768])\n",
      "blocks.7.attn.mask torch.Size([1024, 1024])\n",
      "blocks.7.attn.IGNORE torch.Size([])\n",
      "blocks.7.mlp.W_in torch.Size([768, 3072])\n",
      "blocks.7.mlp.b_in torch.Size([3072])\n",
      "blocks.7.mlp.W_out torch.Size([3072, 768])\n",
      "blocks.7.mlp.b_out torch.Size([768])\n",
      "blocks.8.attn.W_Q torch.Size([12, 768, 64])\n",
      "blocks.8.attn.W_K torch.Size([12, 768, 64])\n",
      "blocks.8.attn.W_V torch.Size([12, 768, 64])\n",
      "blocks.8.attn.W_O torch.Size([12, 64, 768])\n",
      "blocks.8.attn.b_Q torch.Size([12, 64])\n",
      "blocks.8.attn.b_K torch.Size([12, 64])\n",
      "blocks.8.attn.b_V torch.Size([12, 64])\n",
      "blocks.8.attn.b_O torch.Size([768])\n",
      "blocks.8.attn.mask torch.Size([1024, 1024])\n",
      "blocks.8.attn.IGNORE torch.Size([])\n",
      "blocks.8.mlp.W_in torch.Size([768, 3072])\n",
      "blocks.8.mlp.b_in torch.Size([3072])\n",
      "blocks.8.mlp.W_out torch.Size([3072, 768])\n",
      "blocks.8.mlp.b_out torch.Size([768])\n",
      "blocks.9.attn.W_Q torch.Size([12, 768, 64])\n",
      "blocks.9.attn.W_K torch.Size([12, 768, 64])\n",
      "blocks.9.attn.W_V torch.Size([12, 768, 64])\n",
      "blocks.9.attn.W_O torch.Size([12, 64, 768])\n",
      "blocks.9.attn.b_Q torch.Size([12, 64])\n",
      "blocks.9.attn.b_K torch.Size([12, 64])\n",
      "blocks.9.attn.b_V torch.Size([12, 64])\n",
      "blocks.9.attn.b_O torch.Size([768])\n",
      "blocks.9.attn.mask torch.Size([1024, 1024])\n",
      "blocks.9.attn.IGNORE torch.Size([])\n",
      "blocks.9.mlp.W_in torch.Size([768, 3072])\n",
      "blocks.9.mlp.b_in torch.Size([3072])\n",
      "blocks.9.mlp.W_out torch.Size([3072, 768])\n",
      "blocks.9.mlp.b_out torch.Size([768])\n",
      "blocks.10.attn.W_Q torch.Size([12, 768, 64])\n",
      "blocks.10.attn.W_K torch.Size([12, 768, 64])\n",
      "blocks.10.attn.W_V torch.Size([12, 768, 64])\n",
      "blocks.10.attn.W_O torch.Size([12, 64, 768])\n",
      "blocks.10.attn.b_Q torch.Size([12, 64])\n",
      "blocks.10.attn.b_K torch.Size([12, 64])\n",
      "blocks.10.attn.b_V torch.Size([12, 64])\n",
      "blocks.10.attn.b_O torch.Size([768])\n",
      "blocks.10.attn.mask torch.Size([1024, 1024])\n",
      "blocks.10.attn.IGNORE torch.Size([])\n",
      "blocks.10.mlp.W_in torch.Size([768, 3072])\n",
      "blocks.10.mlp.b_in torch.Size([3072])\n",
      "blocks.10.mlp.W_out torch.Size([3072, 768])\n",
      "blocks.10.mlp.b_out torch.Size([768])\n",
      "blocks.11.attn.W_Q torch.Size([12, 768, 64])\n",
      "blocks.11.attn.W_K torch.Size([12, 768, 64])\n",
      "blocks.11.attn.W_V torch.Size([12, 768, 64])\n",
      "blocks.11.attn.W_O torch.Size([12, 64, 768])\n",
      "blocks.11.attn.b_Q torch.Size([12, 64])\n",
      "blocks.11.attn.b_K torch.Size([12, 64])\n",
      "blocks.11.attn.b_V torch.Size([12, 64])\n",
      "blocks.11.attn.b_O torch.Size([768])\n",
      "blocks.11.attn.mask torch.Size([1024, 1024])\n",
      "blocks.11.attn.IGNORE torch.Size([])\n",
      "blocks.11.mlp.W_in torch.Size([768, 3072])\n",
      "blocks.11.mlp.b_in torch.Size([3072])\n",
      "blocks.11.mlp.W_out torch.Size([3072, 768])\n",
      "blocks.11.mlp.b_out torch.Size([768])\n",
      "unembed.W_U torch.Size([768, 50257])\n",
      "unembed.b_U torch.Size([50257])\n",
      "HookedTransformer(\n",
      "  (embed): Embed()\n",
      "  (hook_embed): HookPoint()\n",
      "  (pos_embed): PosEmbed()\n",
      "  (hook_pos_embed): HookPoint()\n",
      "  (blocks): ModuleList(\n",
      "    (0-11): 12 x TransformerBlock(\n",
      "      (ln1): LayerNormPre(\n",
      "        (hook_scale): HookPoint()\n",
      "        (hook_normalized): HookPoint()\n",
      "      )\n",
      "      (ln2): LayerNormPre(\n",
      "        (hook_scale): HookPoint()\n",
      "        (hook_normalized): HookPoint()\n",
      "      )\n",
      "      (attn): Attention(\n",
      "        (hook_k): HookPoint()\n",
      "        (hook_q): HookPoint()\n",
      "        (hook_v): HookPoint()\n",
      "        (hook_z): HookPoint()\n",
      "        (hook_attn_scores): HookPoint()\n",
      "        (hook_pattern): HookPoint()\n",
      "        (hook_result): HookPoint()\n",
      "      )\n",
      "      (mlp): MLP(\n",
      "        (hook_pre): HookPoint()\n",
      "        (hook_post): HookPoint()\n",
      "      )\n",
      "      (hook_attn_in): HookPoint()\n",
      "      (hook_q_input): HookPoint()\n",
      "      (hook_k_input): HookPoint()\n",
      "      (hook_v_input): HookPoint()\n",
      "      (hook_mlp_in): HookPoint()\n",
      "      (hook_attn_out): HookPoint()\n",
      "      (hook_mlp_out): HookPoint()\n",
      "      (hook_resid_pre): HookPoint()\n",
      "      (hook_resid_mid): HookPoint()\n",
      "      (hook_resid_post): HookPoint()\n",
      "    )\n",
      "  )\n",
      "  (ln_final): LayerNormPre(\n",
      "    (hook_scale): HookPoint()\n",
      "    (hook_normalized): HookPoint()\n",
      "  )\n",
      "  (unembed): Unembed()\n",
      ")\n",
      "Parameter containing:\n",
      "tensor([[-0.1101, -0.0393,  0.0331,  ..., -0.1364,  0.0151,  0.0453],\n",
      "        [ 0.0403, -0.0486,  0.0462,  ...,  0.0861,  0.0025,  0.0432],\n",
      "        [-0.1275,  0.0479,  0.1841,  ...,  0.0899, -0.1297, -0.0879],\n",
      "        ...,\n",
      "        [-0.0445, -0.0548,  0.0123,  ...,  0.1044,  0.0978, -0.0695],\n",
      "        [ 0.1860,  0.0167,  0.0461,  ..., -0.0963,  0.0785, -0.0225],\n",
      "        [ 0.0514, -0.0277,  0.0499,  ...,  0.0070,  0.1552,  0.1207]],\n",
      "       device='mps:0', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Extract neuron activations with transformer_lens\n",
    "model_ht = transformer_lens.HookedTransformer.from_pretrained(\"gpt2\", center_writing_weights=False)\n",
    "\n",
    "sd_ht = model_ht.state_dict()\n",
    "for k, v in sd_ht.items():\n",
    "    print(k, v.shape)\n",
    "\n",
    "print(model_ht)\n",
    "print(next(model_ht.parameters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[50256, 31373,   995]], device='mps:0')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ht.to_tokens(\"hello world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device:  mps\n",
      "torch.Size([1, 9, 50257])\n",
      "ActivationCache with keys ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.ln1.hook_scale', 'blocks.0.ln1.hook_normalized', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k', 'blocks.0.attn.hook_v', 'blocks.0.attn.hook_attn_scores', 'blocks.0.attn.hook_pattern', 'blocks.0.attn.hook_z', 'blocks.0.hook_attn_out', 'blocks.0.hook_resid_mid', 'blocks.0.ln2.hook_scale', 'blocks.0.ln2.hook_normalized', 'blocks.0.mlp.hook_pre', 'blocks.0.mlp.hook_post', 'blocks.0.hook_mlp_out', 'blocks.0.hook_resid_post', 'blocks.1.hook_resid_pre', 'blocks.1.ln1.hook_scale', 'blocks.1.ln1.hook_normalized', 'blocks.1.attn.hook_q', 'blocks.1.attn.hook_k', 'blocks.1.attn.hook_v', 'blocks.1.attn.hook_attn_scores', 'blocks.1.attn.hook_pattern', 'blocks.1.attn.hook_z', 'blocks.1.hook_attn_out', 'blocks.1.hook_resid_mid', 'blocks.1.ln2.hook_scale', 'blocks.1.ln2.hook_normalized', 'blocks.1.mlp.hook_pre', 'blocks.1.mlp.hook_post', 'blocks.1.hook_mlp_out', 'blocks.1.hook_resid_post', 'blocks.2.hook_resid_pre', 'blocks.2.ln1.hook_scale', 'blocks.2.ln1.hook_normalized', 'blocks.2.attn.hook_q', 'blocks.2.attn.hook_k', 'blocks.2.attn.hook_v', 'blocks.2.attn.hook_attn_scores', 'blocks.2.attn.hook_pattern', 'blocks.2.attn.hook_z', 'blocks.2.hook_attn_out', 'blocks.2.hook_resid_mid', 'blocks.2.ln2.hook_scale', 'blocks.2.ln2.hook_normalized', 'blocks.2.mlp.hook_pre', 'blocks.2.mlp.hook_post', 'blocks.2.hook_mlp_out', 'blocks.2.hook_resid_post', 'blocks.3.hook_resid_pre', 'blocks.3.ln1.hook_scale', 'blocks.3.ln1.hook_normalized', 'blocks.3.attn.hook_q', 'blocks.3.attn.hook_k', 'blocks.3.attn.hook_v', 'blocks.3.attn.hook_attn_scores', 'blocks.3.attn.hook_pattern', 'blocks.3.attn.hook_z', 'blocks.3.hook_attn_out', 'blocks.3.hook_resid_mid', 'blocks.3.ln2.hook_scale', 'blocks.3.ln2.hook_normalized', 'blocks.3.mlp.hook_pre', 'blocks.3.mlp.hook_post', 'blocks.3.hook_mlp_out', 'blocks.3.hook_resid_post', 'blocks.4.hook_resid_pre', 'blocks.4.ln1.hook_scale', 'blocks.4.ln1.hook_normalized', 'blocks.4.attn.hook_q', 'blocks.4.attn.hook_k', 'blocks.4.attn.hook_v', 'blocks.4.attn.hook_attn_scores', 'blocks.4.attn.hook_pattern', 'blocks.4.attn.hook_z', 'blocks.4.hook_attn_out', 'blocks.4.hook_resid_mid', 'blocks.4.ln2.hook_scale', 'blocks.4.ln2.hook_normalized', 'blocks.4.mlp.hook_pre', 'blocks.4.mlp.hook_post', 'blocks.4.hook_mlp_out', 'blocks.4.hook_resid_post', 'blocks.5.hook_resid_pre', 'blocks.5.ln1.hook_scale', 'blocks.5.ln1.hook_normalized', 'blocks.5.attn.hook_q', 'blocks.5.attn.hook_k', 'blocks.5.attn.hook_v', 'blocks.5.attn.hook_attn_scores', 'blocks.5.attn.hook_pattern', 'blocks.5.attn.hook_z', 'blocks.5.hook_attn_out', 'blocks.5.hook_resid_mid', 'blocks.5.ln2.hook_scale', 'blocks.5.ln2.hook_normalized', 'blocks.5.mlp.hook_pre', 'blocks.5.mlp.hook_post', 'blocks.5.hook_mlp_out', 'blocks.5.hook_resid_post', 'blocks.6.hook_resid_pre', 'blocks.6.ln1.hook_scale', 'blocks.6.ln1.hook_normalized', 'blocks.6.attn.hook_q', 'blocks.6.attn.hook_k', 'blocks.6.attn.hook_v', 'blocks.6.attn.hook_attn_scores', 'blocks.6.attn.hook_pattern', 'blocks.6.attn.hook_z', 'blocks.6.hook_attn_out', 'blocks.6.hook_resid_mid', 'blocks.6.ln2.hook_scale', 'blocks.6.ln2.hook_normalized', 'blocks.6.mlp.hook_pre', 'blocks.6.mlp.hook_post', 'blocks.6.hook_mlp_out', 'blocks.6.hook_resid_post', 'blocks.7.hook_resid_pre', 'blocks.7.ln1.hook_scale', 'blocks.7.ln1.hook_normalized', 'blocks.7.attn.hook_q', 'blocks.7.attn.hook_k', 'blocks.7.attn.hook_v', 'blocks.7.attn.hook_attn_scores', 'blocks.7.attn.hook_pattern', 'blocks.7.attn.hook_z', 'blocks.7.hook_attn_out', 'blocks.7.hook_resid_mid', 'blocks.7.ln2.hook_scale', 'blocks.7.ln2.hook_normalized', 'blocks.7.mlp.hook_pre', 'blocks.7.mlp.hook_post', 'blocks.7.hook_mlp_out', 'blocks.7.hook_resid_post', 'blocks.8.hook_resid_pre', 'blocks.8.ln1.hook_scale', 'blocks.8.ln1.hook_normalized', 'blocks.8.attn.hook_q', 'blocks.8.attn.hook_k', 'blocks.8.attn.hook_v', 'blocks.8.attn.hook_attn_scores', 'blocks.8.attn.hook_pattern', 'blocks.8.attn.hook_z', 'blocks.8.hook_attn_out', 'blocks.8.hook_resid_mid', 'blocks.8.ln2.hook_scale', 'blocks.8.ln2.hook_normalized', 'blocks.8.mlp.hook_pre', 'blocks.8.mlp.hook_post', 'blocks.8.hook_mlp_out', 'blocks.8.hook_resid_post', 'blocks.9.hook_resid_pre', 'blocks.9.ln1.hook_scale', 'blocks.9.ln1.hook_normalized', 'blocks.9.attn.hook_q', 'blocks.9.attn.hook_k', 'blocks.9.attn.hook_v', 'blocks.9.attn.hook_attn_scores', 'blocks.9.attn.hook_pattern', 'blocks.9.attn.hook_z', 'blocks.9.hook_attn_out', 'blocks.9.hook_resid_mid', 'blocks.9.ln2.hook_scale', 'blocks.9.ln2.hook_normalized', 'blocks.9.mlp.hook_pre', 'blocks.9.mlp.hook_post', 'blocks.9.hook_mlp_out', 'blocks.9.hook_resid_post', 'blocks.10.hook_resid_pre', 'blocks.10.ln1.hook_scale', 'blocks.10.ln1.hook_normalized', 'blocks.10.attn.hook_q', 'blocks.10.attn.hook_k', 'blocks.10.attn.hook_v', 'blocks.10.attn.hook_attn_scores', 'blocks.10.attn.hook_pattern', 'blocks.10.attn.hook_z', 'blocks.10.hook_attn_out', 'blocks.10.hook_resid_mid', 'blocks.10.ln2.hook_scale', 'blocks.10.ln2.hook_normalized', 'blocks.10.mlp.hook_pre', 'blocks.10.mlp.hook_post', 'blocks.10.hook_mlp_out', 'blocks.10.hook_resid_post', 'blocks.11.hook_resid_pre', 'blocks.11.ln1.hook_scale', 'blocks.11.ln1.hook_normalized', 'blocks.11.attn.hook_q', 'blocks.11.attn.hook_k', 'blocks.11.attn.hook_v', 'blocks.11.attn.hook_attn_scores', 'blocks.11.attn.hook_pattern', 'blocks.11.attn.hook_z', 'blocks.11.hook_attn_out', 'blocks.11.hook_resid_mid', 'blocks.11.ln2.hook_scale', 'blocks.11.ln2.hook_normalized', 'blocks.11.mlp.hook_pre', 'blocks.11.mlp.hook_post', 'blocks.11.hook_mlp_out', 'blocks.11.hook_resid_post', 'ln_final.hook_scale', 'ln_final.hook_normalized']\n"
     ]
    }
   ],
   "source": [
    "#attempt to autodetect device\n",
    "device = \"cpu\"\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "elif hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available():\n",
    "    device = \"mps\"  \n",
    "print(\"Using device: \", device)\n",
    "\n",
    "prompt = \"This is an example of a prompt that\"\n",
    "tokens = model_ht.to_tokens(prompt)  # (1, n_tokens)\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits, activation_cache = model_ht.run_with_cache(tokens, remove_batch_dim=True)\n",
    "\n",
    "print(logits.size())\n",
    "print(activation_cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformer_lens_loc : blocks.6.hook_resid_post\n"
     ]
    }
   ],
   "source": [
    "layer_index = 6\n",
    "location = \"resid_post_mlp\"\n",
    "\n",
    "transformer_lens_loc = {\n",
    "    \"mlp_post_act\": f\"blocks.{layer_index}.mlp.hook_post\",\n",
    "    \"resid_delta_attn\": f\"blocks.{layer_index}.hook_attn_out\",\n",
    "    \"resid_post_attn\": f\"blocks.{layer_index}.hook_resid_mid\",\n",
    "    \"resid_delta_mlp\": f\"blocks.{layer_index}.hook_mlp_out\",\n",
    "    \"resid_post_mlp\": f\"blocks.{layer_index}.hook_resid_post\",\n",
    "}[location]\n",
    "\n",
    "print(\"transformer_lens_loc :\", transformer_lens_loc)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre_bias torch.Size([768])\n",
      "latent_bias torch.Size([32768])\n",
      "stats_last_nonzero torch.Size([32768])\n",
      "latents_activation_frequency torch.Size([32768])\n",
      "latents_mean_square torch.Size([32768])\n",
      "encoder.weight torch.Size([32768, 768])\n",
      "activation.k 32\n",
      "activation.postact_fn ReLU\n",
      "decoder.weight torch.Size([768, 32768])\n",
      "activation TopK\n",
      "activation_state_dict OrderedDict([('k', 32), ('postact_fn', 'ReLU')])\n",
      "Autoencoder(\n",
      "  (encoder): Linear(in_features=768, out_features=32768, bias=False)\n",
      "  (activation): TopK(\n",
      "    (postact_fn): ReLU()\n",
      "  )\n",
      "  (decoder): Linear(in_features=32768, out_features=768, bias=False)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/patila06/.pyenv/versions/3.10.12/envs/build_sparse_autoencoder_venv_310/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "with bf.BlobFile(sparse_autoencoder.paths.v5_32k(location, layer_index), mode=\"rb\") as f:\n",
    "    state_dict = torch.load(f)\n",
    "    autoencoder = sparse_autoencoder.Autoencoder.from_state_dict(state_dict)\n",
    "    autoencoder.to(device)\n",
    "\n",
    "\n",
    "sd_oa = autoencoder.state_dict()\n",
    "\n",
    "for k, v in sd_oa.items():\n",
    "    if type(v) == torch.Tensor:\n",
    "        print(k, v.shape)\n",
    "    else:\n",
    "        print(k, v)\n",
    "\n",
    "print(autoencoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input tensor  torch.Size([9, 768])\n",
      "latent_activations:  torch.Size([9, 32768])\n",
      "info:  {'mu': tensor([[4.7377],\n",
      "        [0.0663],\n",
      "        [0.0386],\n",
      "        [0.0584],\n",
      "        [0.0425],\n",
      "        [0.0338],\n",
      "        [0.0644],\n",
      "        [0.0438],\n",
      "        [0.0534]], device='mps:0'), 'std': tensor([[111.3588],\n",
      "        [  3.3521],\n",
      "        [  3.2112],\n",
      "        [  3.0729],\n",
      "        [  3.3707],\n",
      "        [  3.0138],\n",
      "        [  2.8864],\n",
      "        [  3.6442],\n",
      "        [  3.2611]], device='mps:0')}\n",
      "reconstructed_activations:  torch.Size([9, 768])\n",
      "resid_post_mlp tensor([6.4424e-05, 3.9219e-02, 3.1569e-02, 4.6317e-02, 7.1058e-02, 4.7744e-02,\n",
      "        6.2675e-02, 6.7039e-02, 7.5507e-02], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "input_tensor = activation_cache[transformer_lens_loc]\n",
    "\n",
    "print(\"input tensor \", input_tensor.shape)\n",
    "\n",
    "with torch.no_grad():\n",
    "    latent_activations, info = autoencoder.encode(input_tensor)\n",
    "    print(\"latent_activations: \", latent_activations.shape)\n",
    "    print(\"info: \",info)\n",
    "    reconstructed_activations = autoencoder.decode(latent_activations, info)\n",
    "    print(\"reconstructed_activations: \", reconstructed_activations.shape)\n",
    "\n",
    "normalized_mse = (reconstructed_activations - input_tensor).pow(2).sum(dim=1) / (input_tensor).pow(2).sum(dim=1)\n",
    "print(location, normalized_mse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "build_sparse_autoencoder_venv_310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
